rm(list = ls())

####
#all
####

library(ggpubr)
library(tidyverse)

#Here, set the file name of the table generated by get_seq_lengths.py
sample.filename = "data/test_seq_lengths.txt"

#use their script to import to ensure correct ref lengths
sample.data = as.matrix(read.table(
  sample.filename,
  header = T,
  row.names = 1,
  sep = "\t"
))

#remove X from locus name
colnames(sample.data) <- gsub("X", "", colnames(sample.data))

#view data
#view(sample.data)

#set length of reference exon
reference.len = as.numeric(sample.data[1, ])

#extract only sample exon lengths
sample.len = sample.data[2:length(sample.data[, 1]), ]

#calculate percentage of exon recovered for each exon in each individual
percent.len = sweep(sample.len, 2, reference.len, "/")
percent.len = ifelse(percent.len > 1, 1, percent.len)

#look at data
head(percent.len[, c(1:5)])

#user input threshold
lim <- 0.5

#vector to store greps
sed_cmds <- vector()
k <- 1

#i = number of rows
#j = number of columns

#go through all cells in table and pull out those
#combinations of individual/exon that are lower than threshold
for (i in 1:length(percent.len[, 1])) {
  for (j in 1:length(percent.len[1, ])) {
    if (percent.len[i, j] < lim) {
      print(rownames(percent.len)[i])
      print(colnames(percent.len)[j])

      #sed '/Asie/{N;d;}'

      sed_cmds[k] <-
        paste(
          "sed '/",
          rownames(percent.len)[i],
          "/{N;d;}' header.",
          colnames(percent.len)[j],
          "_supercontig.FNA > reduced.header.",
          colnames(percent.len)[j],
          "_supercontig.FNA",
          sep = ""
        )
      k <- k + 1

    }
  }

  #renames files so they can be modified for the next individual
  sed_cmds[k]<-paste('rename "reduced." "" *')
  k <- k + 1

}

#numbers should be the same
length(sed_cmds)
table(percent.len < lim)[2] + length(rownames(percent.len))

#output to file
cat(
  x = paste0(sed_cmds),
  file = "outputs/low_length_exon_removal_50.txt",
  sep = "\n"
)

